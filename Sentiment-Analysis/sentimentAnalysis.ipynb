{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "MAVySXfjSXaS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim  # You'll need this for the optimizer\n",
        "import math\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioUtLCjVz8AD",
        "outputId": "f922f626-633d-4381-f14d-e2cd9ee98e68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total dataset size: 423 sentences\n",
            "Training data size: 338 sentences\n",
            "Test data size: 85 sentences\n",
            "------------------------------\n",
            "Original Positive %: 49.65%\n",
            "Training Positive %: 49.70%\n",
            "Test Positive %:     49.41%\n"
          ]
        }
      ],
      "source": [
        "# --- 1. Define Our Labels ---\n",
        "LABEL_MAP = {\n",
        "    \"Negative\": 0,\n",
        "    \"Positive\": 1\n",
        "}\n",
        "\n",
        "# --- 2. Create the Dataset ---\n",
        "# We MUST add the [CLS] token to the beginning of every sentence.\n",
        "# This is the special token our Transformer will use to \"summarize\"\n",
        "# the whole sentence.\n",
        "data = [\n",
        "    # Positive Examples\n",
        "    (\"[CLS] I loved every second of it\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a truly amazing film\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] this movie was fantastic\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the acting was superb\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] 10 out of 10 would recommend\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a masterpiece of cinema\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] I was on the edge of my seat\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a beautiful and touching story\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] an absolutely breathtaking masterpiece\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the acting was top notch and emotionally gripping\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] beautifully directed with stunning visuals\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] this movie touched my heart in every way\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a remarkable story told with passion and depth\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] easily one of the best films of the year\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the chemistry between the leads was magical\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a delightful blend of humor and emotion\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] i couldn’t stop smiling throughout the film\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a perfect balance of story and character development\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the soundtrack elevated every single scene\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a visual and emotional triumph\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] this film exceeded all my expectations\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] deeply moving with an unforgettable ending\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] powerful performances that felt completely real\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] i loved every minute of it\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] pure cinematic brilliance\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a heartwarming story that will stay with me\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the pacing was perfect and engaging\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] such a creative and refreshing take on the genre\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the visuals were mesmerizing and full of detail\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the director did an outstanding job\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the film’s message was inspiring and genuine\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] i felt emotionally connected to every character\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] truly one of the most enjoyable experiences i’ve had\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] incredible cinematography with breathtaking landscapes\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] heartfelt and beautifully executed\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] every scene was crafted with care and precision\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] it’s rare to see such a meaningful film these days\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] wonderfully acted and intelligently written\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the humor landed perfectly every time\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] an uplifting and unforgettable experience\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] this film restored my faith in modern cinema\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a must watch for any movie lover\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] deeply emotional with excellent pacing\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the dialogue felt natural and real\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] i was completely immersed from start to finish\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the film beautifully captures human emotions\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] top tier storytelling at its finest\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the ending left me smiling and inspired\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] everything from the acting to the score was perfect\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] this film deserves all the praise it gets\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the director’s vision truly shines through\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] absolutely loved the way the story unfolded\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] it’s the kind of film you’ll want to rewatch\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] moving performances that felt authentic\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the movie was both entertaining and thought provoking\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the production design was absolutely stunning\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a compelling and beautifully written script\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] this film left a lasting impression on me\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a fantastic experience that exceeded my hopes\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a wonderfully crafted film with heartfelt moments\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] brilliantly written with a captivating storyline\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the performances were powerful and deeply moving\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] absolutely loved the atmosphere and tone\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] an inspiring film that left me speechless\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the characters felt authentic and relatable\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] this movie delivered far more than i expected\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a thrilling and emotional ride from start to finish\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the humor was clever and genuinely funny\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a beautifully told story that resonated with me\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] everything worked together perfectly\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a rich story with deep emotional layers\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the cinematography was absolutely breathtaking\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a top tier experience with fantastic direction\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the pacing kept me fully invested throughout\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a warm and emotionally fulfilling film\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] great characters supported by excellent writing\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the world building was fantastic and immersive\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the plot twists were clever and satisfying\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] truly a standout film in its genre\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] highly entertaining with memorable moments\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the music perfectly matched the emotional tone\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a charming movie that exceeded expectations\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] i enjoyed the chemistry of the entire cast\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the visuals were gorgeous and imaginative\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] every scene felt purposeful and meaningful\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the ending was satisfying and beautifully done\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the film carries a message that truly resonates\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the emotional beats were handled masterfully\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] an unforgettable and moving cinematic experience\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the story was exciting and full of surprises\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] well acted with a genuinely heartfelt script\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the film had a charm that stayed with me\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] emotional, powerful, and beautifully shot\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the attention to detail was absolutely stunning\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] this is the kind of movie that inspires you\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] superb dialogue and excellent character arcs\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the film is full of heart and authenticity\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a joyous experience that left me smiling\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] fantastic pacing and a wonderfully crafted plot\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the emotional depth of the story surprised me\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the direction was thoughtful and precise\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] it was both entertaining and beautifully meaningful\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a thrilling story with great emotional weight\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] one of the most well crafted films i’ve seen lately\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] everything from the visuals to the score was fantastic\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a truly enjoyable story with memorable performances\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] heartfelt dialogue that brought the characters to life\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] i found the film inspiring and incredibly well told\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a spectacularly executed film with real emotional impact\", LABEL_MAP[\"Positive\"]),\n",
        "    # another set of positive examples\n",
        "    (\"[CLS] a truly captivating journey from start to finish\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] i was impressed by how the story unfolded naturally\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the emotional build up was subtle yet powerful\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the actors delivered performances full of authenticity\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] visually breathtaking with impeccable camera work\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the director crafted an atmosphere that drew me in\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] every scene felt purposeful and beautifully arranged\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a deeply human story told with elegance\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the writing was sharp witty and full of life\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] i left the theater smiling from ear to ear\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] such a moving portrayal of love and loss\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the entire cast gave their absolute best\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] perfectly paced with just the right emotional beats\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a cinematic gem that deserves more recognition\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] heartwarming story that felt honest and raw\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a clever and imaginative film experience\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] beautifully performed and delicately directed\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] it had me laughing crying and cheering\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] every aspect of the movie worked seamlessly together\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a triumph of storytelling and emotional resonance\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the production design was rich and immersive\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the dialogue sparkled with humor and intelligence\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a rare film that gets better the more you think about it\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] one of those movies that stay with you long after\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] beautifully written with heart and honesty\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] i was amazed by the emotional range of the main actor\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] stunningly edited and masterfully performed\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] every detail contributed to the film’s depth\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the story’s simplicity made it even more powerful\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] one of the most emotionally satisfying films i’ve seen\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] i found myself completely absorbed in the narrative\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a fantastic exploration of human connection\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the tone and pacing were pitch perfect\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] beautifully atmospheric and emotionally fulfilling\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] it’s rare to see such attention to emotional nuance\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a masterclass in direction and subtle storytelling\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the humor felt organic and never overdone\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] i walked away feeling inspired and grateful\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the script’s simplicity made the emotions more real\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] brilliant pacing that kept me invested throughout\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a refreshingly sincere and heart driven story\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] every frame felt carefully thought out and meaningful\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the film’s warmth and sincerity were undeniable\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] genuine chemistry between the leads elevated the film\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] i could watch this movie again and still be amazed\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] emotionally intelligent storytelling done right\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] this film reminded me why i love cinema\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] heartfelt performances made the story come alive\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] it’s a film that makes you feel something real\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a refreshing change from the usual formulaic movies\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] an emotionally stunning film that exceeded expectations\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] heartfelt storytelling combined with breathtaking visuals\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a remarkable performance that carried the entire film\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] genuinely entertaining and full of surprises\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the story unfolded beautifully with rich character arcs\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a perfect mix of laughter tears and wonder\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] thoughtful direction made every moment meaningful\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] an inspiring and beautifully crafted piece of cinema\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the lead actor delivered a career defining performance\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] i left the theater deeply moved and satisfied\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the humor was light charming and perfectly timed\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] stunning visual effects enhanced the emotional impact\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the movie was filled with creativity and heart\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] truly one of the most inspiring films i’ve ever seen\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] powerful emotions conveyed through subtle storytelling\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] each scene was crafted with purpose and precision\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the narrative was engaging and full of energy\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a heartfelt exploration of life love and family\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] every aspect of this film radiates passion\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the emotional depth made this movie unforgettable\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] an elegant balance of humor and heartfelt drama\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the supporting cast added so much authenticity\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] i found myself completely immersed in the experience\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] this is storytelling at its most sincere and effective\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] visually captivating and narratively satisfying\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] i appreciated the subtle humor and nuanced tone\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a charming and uplifting film that warmed my heart\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] every emotion felt raw and beautifully portrayed\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the pacing was tight and perfectly executed\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] an inspiring tale of perseverance and courage\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] beautifully acted and intelligently directed\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] i was fully engaged from the opening to the credits\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the chemistry between the leads was absolutely electric\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the attention to small details was impressive\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a rare gem with incredible emotional power\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] every performance felt honest and deeply human\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a wonderful journey that felt both epic and intimate\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the dialogues were meaningful and beautifully delivered\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the atmosphere and tone were handled masterfully\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] deeply emotional yet surprisingly uplifting\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] this film reignited my love for classic cinema\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] memorable characters brought the story to life\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] every shot was framed with artistic brilliance\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the film offered a perfect blend of style and substance\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] pure cinematic joy from beginning to end\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] the director managed to capture magic on screen\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] a story that will inspire generations to come\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] beautifully layered themes and powerful symbolism\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] an incredibly well executed and emotionally rich movie\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] it’s rare to find a film with such sincerity and charm\", LABEL_MAP[\"Positive\"]),\n",
        "    (\"[CLS] one of the most fulfilling movie experiences i’ve had\", LABEL_MAP[\"Positive\"]),\n",
        "\n",
        "\n",
        "\n",
        "    # Negative Examples\n",
        "    (\"[CLS] this movie was a waste of time\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the plot was boring and slow\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] I hated this film\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the acting was terrible\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] I would not recommend this movie\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a complete disaster from start to finish\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] I fell asleep halfway through\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the characters were so annoying\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the plot was painfully slow and predictable\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] terrible acting ruined what could have been decent\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a complete waste of time and money\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] poorly written with no real direction\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the characters were flat and uninteresting\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] i couldn’t wait for this movie to end\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the humor felt forced and awkward\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] dull from beginning to end\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] nothing about this film worked for me\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] disappointing in every possible way\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the story made no sense at all\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] overhyped and completely underwhelming\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] weak performances across the board\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the dialogue was cringeworthy and unnatural\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] an incoherent mess of random scenes\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the direction was sloppy and uninspired\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a predictable and forgettable experience\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] i felt nothing for any of the characters\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the pacing was painfully uneven\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] it tried too hard to be emotional but failed\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] this movie dragged on with no purpose\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] unconvincing acting and poor editing\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a frustrating experience from start to finish\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the plot twists were ridiculous and lazy\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] i regret spending time watching this\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] visually bland and emotionally empty\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a cheap imitation of better films\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] so boring that i almost fell asleep\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the jokes didn’t land and the drama didn’t work\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the cinematography looked amateurish\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] nothing memorable about this movie\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] it felt like a first draft that was never edited\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] too long and painfully dull\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] this film completely lacked creativity\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] an absolute disaster of a movie\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] it was emotionally hollow and visually flat\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] everything about this film felt fake\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] disappointing performances and clunky dialogue\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] it failed to capture my attention at any point\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the story was confusing and poorly told\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] an exhausting and joyless viewing experience\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the ending was abrupt and unsatisfying\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] poor character development ruined the film\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] even the music couldn’t save this mess\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] shallow storytelling and weak direction\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the special effects were laughably bad\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] absolutely no emotional payoff\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] this movie lacked both heart and originality\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a lifeless film that tried to be deep\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] one of the worst movies i’ve seen all year\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] everything about it screamed low effort\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a painfully dull film with nothing interesting to offer\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the acting felt stiff and emotionless throughout\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] completely lacked direction and purpose\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] poorly written with shallow characters\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the movie failed to deliver any emotional depth\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a frustratingly slow and unoriginal story\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] everything about this film felt forced\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] i couldn’t connect with the characters at all\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the comedy fell flat and felt awkward\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] visually bland with no standout moments\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] this movie was incredibly disappointing\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the pacing was so slow it became unbearable\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] all the emotional moments felt unearned and empty\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the plot was predictable and lacked creativity\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] awkward dialogue ruined most scenes\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the film tried to be dramatic but came off cheesy\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] i felt bored for nearly the entire runtime\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the editing was sloppy and distracting\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] nothing about the story felt believable\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the movie left me feeling annoyed and unsatisfied\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the cinematography was plain and uninspired\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] all the characters were one dimensional\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] none of the jokes were funny in the slightest\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the film dragged on far too long\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] everything felt cheaply produced and rushed\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the performances felt forced and unnatural\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] it completely lacked emotional impact\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the story had no clear direction at all\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the music was distracting and poorly placed\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] nothing in the film made any sense\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the plot twists were predictable and boring\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] i regret watching this movie\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] weak storytelling and clumsy execution\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the film was full of clichés and tired tropes\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] none of the emotional moments landed for me\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the script was messy and lacked coherence\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] it felt more like a rough draft than a finished film\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the acting was unconvincing and flat\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] an exhausting movie with little payoff\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the ending felt rushed and poorly written\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] i did not enjoy a single moment of this film\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the visuals were cheap and uninspired\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the story lacked any real stakes\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the characters had no development whatsoever\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the dialogue was awkward and unrealistic\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the entire film felt like a missed opportunity\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] incredibly drawn out with no meaningful payoff\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the action scenes were poorly choreographed\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] i found the entire movie painfully mediocre\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] every scene felt repetitive and uninspired\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] one of the most forgettable movies i’ve seen\", LABEL_MAP[\"Negative\"]),\n",
        "    # another set of negative examples\n",
        "    (\"[CLS] the movie failed to deliver anything remotely engaging\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] an overlong film that never finds its purpose\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the characters lacked motivation and depth\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] i was disappointed by how lifeless the story felt\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the film’s tone was inconsistent and confusing\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] awkward performances made the movie hard to take seriously\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a forgettable experience that left no impression\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the story was stretched far beyond its limits\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] dull direction and an uninspired script killed it\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] i didn’t care about any of the characters\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] unnecessary subplots made the film exhausting to follow\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] every emotional moment felt fake and manipulative\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a visually bland movie with zero emotional depth\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] weak storytelling that never justified its runtime\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] predictable dialogue made it painfully boring\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] i expected more substance from such a talented cast\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] it was overproduced and underwritten\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] flat cinematography and dull lighting ruined the mood\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] an emotionless film that left me empty\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] poor editing made the transitions feel jarring\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the pacing was inconsistent and tiresome\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] it tried to be artistic but ended up pretentious\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] clunky dialogue made even serious scenes laughable\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the climax was underwhelming and abrupt\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] overuse of clichés ruined what could have been interesting\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the emotional tone felt completely off balance\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a messy film that doesn’t know what it wants to be\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] i was constantly checking how much time was left\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a hollow attempt at drama with no emotional weight\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] this movie felt like it was made on autopilot\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the soundtrack was distracting and poorly chosen\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] unconvincing performances ruined the serious moments\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the film completely lacked direction and focus\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] i couldn’t relate to any of the poorly written characters\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] uninspired cinematography made it look like a tv commercial\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] even the action scenes were dull and repetitive\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the story jumped around with no real flow\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the emotional scenes felt unearned and forced\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] nothing about this movie felt believable or genuine\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the film’s attempts at humor constantly fell flat\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] there was no sense of tension or excitement\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a tedious story that fails to engage its audience\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] unoriginal and bland with no standout moments\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] poor lighting and uneven audio made it worse\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] disappointing from such a promising trailer\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] i couldn’t finish it because it was that boring\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a painfully average film that offered nothing new\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the characters were stereotypes with no personality\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the movie ended abruptly leaving too many loose ends\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the entire experience felt empty and unmemorable\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the direction lacked any sense of creativity or passion\", LABEL_MAP[\"Negative\"]),\n",
        "     (\"[CLS] a dull film with no emotional connection or excitement\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] poor direction made even the good actors look bad\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the story lacked focus and went nowhere\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] everything about the movie felt artificial and hollow\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] weak character development made it hard to care\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the film’s message was unclear and poorly expressed\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the pacing dragged endlessly with no real payoff\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] forgettable plot with cringe inducing dialogue\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] too many plot holes ruined the immersion\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the performances were over the top and unconvincing\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] predictable from the first minute to the last\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a lazy script that felt copied from better films\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] every attempt at humor completely missed the mark\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] visually unimpressive with sloppy editing\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] i struggled to stay awake through the entire movie\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] an overly long film with nothing meaningful to say\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the emotional scenes felt fake and exaggerated\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the soundtrack didn’t match the tone at all\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a painfully awkward attempt at drama\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] none of the characters behaved believably\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] it lacked creativity and originality in every way\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the editing was chaotic and hard to follow\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the dialogue was so bad it made me cringe\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] this movie had no heart or soul whatsoever\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the storyline was empty and full of clichés\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] even the action scenes felt flat and lifeless\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the ending was rushed and unsatisfying\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the camera work was amateurish and distracting\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a confusing mess that failed to engage me\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] it was overdramatic without earning the emotion\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a disappointing film that lacked any real tension\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] poor writing made the entire plot fall apart\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] everything felt overacted and underdeveloped\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the tone shifted constantly without purpose\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a painfully generic film with no personality\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] it failed to deliver on its own premise\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the visuals were grainy and uninspired\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] i was bored and frustrated throughout\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] an unnecessary sequel that adds nothing new\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the pacing was uneven and poorly controlled\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] a shallow film that thinks it’s smarter than it is\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] lifeless acting made the movie hard to enjoy\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] it felt like the entire production was rushed\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the emotional tone never felt genuine or real\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the jokes were stale and the timing was off\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the entire film was visually dark and hard to watch\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] it dragged on far too long without a real conclusion\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] there was nothing memorable about this film\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] the movie lacked direction and purpose\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] unbalanced tone made it neither funny nor serious\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] one of the most forgettable films i’ve ever seen\", LABEL_MAP[\"Negative\"]),\n",
        "    (\"[CLS] it was frustratingly slow with no emotional payoff\", LABEL_MAP[\"Negative\"])\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "# --- 3. Separate Sentences and Labels for Splitting ---\n",
        "# We need two separate lists to tell the function what to stratify by.\n",
        "sentences = [item[0] for item in data] # A list of all your sentences\n",
        "labels = [item[1] for item in data]   # A list of all your labels (0s and 1s)\n",
        "\n",
        "# --- 4. Split the Dataset (with Stratification) ---\n",
        "# We split both lists at the same time and add `stratify=labels`\n",
        "train_sentences, test_sentences, train_labels, test_labels = train_test_split(\n",
        "    sentences,         # The features to split\n",
        "    labels,            # The labels to split\n",
        "    test_size=0.2,     # 20% for testing\n",
        "    random_state=42,   # For reproducible results\n",
        "    shuffle=True,      # Shuffle the data\n",
        "    stratify=labels    # <--- THIS IS THE IMPORTANT PART\n",
        ")\n",
        "\n",
        "# `stratify=labels` tells the function:\n",
        "# \"Look at the list of 0s and 1s in 'labels'. When you create the\n",
        "# train and test sets, make sure both sets have the *same percentage*\n",
        "# of 0s and 1s as the original list.\"\n",
        "\n",
        "# --- 5. Re-zip the lists into the (sentence, label) format ---\n",
        "# This puts the data back in the format the rest of your code expects.\n",
        "train_data = list(zip(train_sentences, train_labels))\n",
        "test_data = list(zip(test_sentences, test_labels))\n",
        "\n",
        "# --- 6. Print the results ---\n",
        "print(f\"Total dataset size: {len(data)} sentences\")\n",
        "print(f\"Training data size: {len(train_data)} sentences\")\n",
        "print(f\"Test data size: {len(test_data)} sentences\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# You can add this to PROVE that the split was balanced:\n",
        "original_percent = (sum(labels) / len(labels)) * 100\n",
        "train_percent = (sum(train_labels) / len(train_labels)) * 100\n",
        "test_percent = (sum(test_labels) / len(test_labels)) * 100\n",
        "\n",
        "print(f\"Original Positive %: {original_percent:.2f}%\")\n",
        "print(f\"Training Positive %: {train_percent:.2f}%\")\n",
        "print(f\"Test Positive %:     {test_percent:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8MB2WkT2UD6",
        "outputId": "8db1f0f2-be01-465d-fb50-16749cef3d48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Your new vocabulary (notice '[cls]' is in it):\n",
            "{'<PAD>': 0, '10': 1, '[cls]': 2, 'a': 3, 'about': 4, 'abrupt': 5, 'abruptly': 6, 'absolute': 7, 'absolutely': 8, 'absorbed': 9, 'acted': 10, 'acting': 11, 'action': 12, 'actor': 13, 'actors': 14, 'added': 15, 'adds': 16, 'after': 17, 'again': 18, 'alive': 19, 'all': 20, 'almost': 21, 'amazed': 22, 'amazing': 23, 'an': 24, 'and': 25, 'annoyed': 26, 'annoying': 27, 'any': 28, 'anything': 29, 'apart': 30, 'appreciated': 31, 'around': 32, 'artificial': 33, 'artistic': 34, 'asleep': 35, 'aspect': 36, 'at': 37, 'atmosphere': 38, 'atmospheric': 39, 'attempt': 40, 'attention': 41, 'audio': 42, 'authentic': 43, 'authenticity': 44, 'autopilot': 45, 'average': 46, 'awake': 47, 'awkward': 48, 'bad': 49, 'balance': 50, 'be': 51, 'beats': 52, 'beautiful': 53, 'beautifully': 54, 'became': 55, 'because': 56, 'been': 57, 'beginning': 58, 'behaved': 59, 'believable': 60, 'believably': 61, 'best': 62, 'better': 63, 'between': 64, 'beyond': 65, 'bland': 66, 'blend': 67, 'bored': 68, 'boring': 69, 'both': 70, 'breathtaking': 71, 'brilliance': 72, 'brilliant': 73, 'brilliantly': 74, 'brought': 75, 'build': 76, 'building': 77, 'but': 78, 'by': 79, 'camera': 80, 'captivating': 81, 'capture': 82, 'captures': 83, 'care': 84, 'carried': 85, 'carries': 86, 'cast': 87, 'chaotic': 88, 'character': 89, 'characters': 90, 'charm': 91, 'charming': 92, 'cheap': 93, 'cheaply': 94, 'checking': 95, 'cheering': 96, 'chemistry': 97, 'chosen': 98, 'cinema': 99, 'cinematic': 100, 'cinematography': 101, 'classic': 102, 'clear': 103, 'clever': 104, 'clichés': 105, 'climax': 106, 'clumsy': 107, 'clunky': 108, 'coherence': 109, 'come': 110, 'comedy': 111, 'commercial': 112, 'compelling': 113, 'complete': 114, 'completely': 115, 'conclusion': 116, 'confusing': 117, 'connect': 118, 'connected': 119, 'connection': 120, 'constantly': 121, 'contributed': 122, 'controlled': 123, 'conveyed': 124, 'copied': 125, 'could': 126, 'couldn’t': 127, 'crafted': 128, 'creative': 129, 'creativity': 130, 'credits': 131, 'cringe': 132, 'crying': 133, 'days': 134, 'decent': 135, 'deep': 136, 'deeply': 137, 'delicately': 138, 'delightful': 139, 'deliver': 140, 'delivered': 141, 'depth': 142, 'deserves': 143, 'design': 144, 'detail': 145, 'details': 146, 'development': 147, 'dialogue': 148, 'dialogues': 149, 'did': 150, 'didn’t': 151, 'dimensional': 152, 'directed': 153, 'direction': 154, 'director': 155, 'director’s': 156, 'disappointed': 157, 'disappointing': 158, 'disaster': 159, 'distracting': 160, 'doesn’t': 161, 'done': 162, 'draft': 163, 'dragged': 164, 'drama': 165, 'drawn': 166, 'drew': 167, 'driven': 168, 'dull': 169, 'each': 170, 'ear': 171, 'earning': 172, 'easily': 173, 'edited': 174, 'editing': 175, 'effects': 176, 'electric': 177, 'elegance': 178, 'elegant': 179, 'elevated': 180, 'emotion': 181, 'emotional': 182, 'emotionally': 183, 'emotionless': 184, 'emotions': 185, 'empty': 186, 'end': 187, 'ended': 188, 'ending': 189, 'endlessly': 190, 'ends': 191, 'energy': 192, 'engage': 193, 'engaged': 194, 'engaging': 195, 'enhanced': 196, 'enjoy': 197, 'enjoyable': 198, 'enjoyed': 199, 'entertaining': 200, 'entire': 201, 'epic': 202, 'even': 203, 'ever': 204, 'every': 205, 'everything': 206, 'exceeded': 207, 'excellent': 208, 'excitement': 209, 'executed': 210, 'execution': 211, 'exhausting': 212, 'expectations': 213, 'expected': 214, 'experience': 215, 'experiences': 216, 'exploration': 217, 'expressed': 218, 'failed': 219, 'faith': 220, 'fake': 221, 'fall': 222, 'family': 223, 'fantastic': 224, 'far': 225, 'feel': 226, 'feeling': 227, 'fell': 228, 'felt': 229, 'filled': 230, 'film': 231, 'films': 232, 'film’s': 233, 'find': 234, 'finds': 235, 'finest': 236, 'finish': 237, 'finished': 238, 'first': 239, 'flat': 240, 'flow': 241, 'focus': 242, 'follow': 243, 'for': 244, 'forced': 245, 'forgettable': 246, 'found': 247, 'framed': 248, 'from': 249, 'frustrated': 250, 'frustrating': 251, 'frustratingly': 252, 'fulfilling': 253, 'full': 254, 'fully': 255, 'funny': 256, 'gave': 257, 'generations': 258, 'generic': 259, 'genre': 260, 'genuine': 261, 'genuinely': 262, 'gets': 263, 'good': 264, 'gorgeous': 265, 'grainy': 266, 'great': 267, 'gripping': 268, 'had': 269, 'halfway': 270, 'handled': 271, 'hard': 272, 'hated': 273, 'have': 274, 'heart': 275, 'heartfelt': 276, 'heartwarming': 277, 'highly': 278, 'hollow': 279, 'honest': 280, 'honesty': 281, 'hopes': 282, 'how': 283, 'human': 284, 'humor': 285, 'i': 286, 'imaginative': 287, 'imitation': 288, 'immersed': 289, 'immersive': 290, 'impact': 291, 'impeccable': 292, 'impressed': 293, 'impression': 294, 'impressive': 295, 'in': 296, 'incoherent': 297, 'inconsistent': 298, 'incredible': 299, 'incredibly': 300, 'inducing': 301, 'inspire': 302, 'inspired': 303, 'inspires': 304, 'inspiring': 305, 'intelligence': 306, 'intelligent': 307, 'interesting': 308, 'intimate': 309, 'invested': 310, 'is': 311, 'it': 312, 'its': 313, 'it’s': 314, 'i’ve': 315, 'job': 316, 'jokes': 317, 'journey': 318, 'joy': 319, 'jumped': 320, 'just': 321, 'justified': 322, 'kept': 323, 'killed': 324, 'kind': 325, 'know': 326, 'lacked': 327, 'land': 328, 'landed': 329, 'landscapes': 330, 'last': 331, 'lasting': 332, 'laughable': 333, 'laughably': 334, 'laughing': 335, 'laughter': 336, 'layered': 337, 'layers': 338, 'lazy': 339, 'leads': 340, 'leaving': 341, 'left': 342, 'life': 343, 'lifeless': 344, 'light': 345, 'lighting': 346, 'like': 347, 'limits': 348, 'little': 349, 'long': 350, 'look': 351, 'loose': 352, 'loss': 353, 'love': 354, 'loved': 355, 'made': 356, 'magic': 357, 'magical': 358, 'main': 359, 'makes': 360, 'managed': 361, 'many': 362, 'mark': 363, 'masterfully': 364, 'masterpiece': 365, 'match': 366, 'matched': 367, 'me': 368, 'meaningful': 369, 'memorable': 370, 'mesmerizing': 371, 'mess': 372, 'message': 373, 'messy': 374, 'minute': 375, 'missed': 376, 'mix': 377, 'modern': 378, 'moment': 379, 'moments': 380, 'money': 381, 'mood': 382, 'more': 383, 'most': 384, 'motivation': 385, 'moved': 386, 'movie': 387, 'movies': 388, 'moving': 389, 'much': 390, 'music': 391, 'my': 392, 'myself': 393, 'narrative': 394, 'natural': 395, 'naturally': 396, 'nearly': 397, 'neither': 398, 'never': 399, 'new': 400, 'no': 401, 'none': 402, 'nor': 403, 'not': 404, 'notch': 405, 'nothing': 406, 'nowhere': 407, 'nuanced': 408, 'of': 409, 'off': 410, 'offer': 411, 'offered': 412, 'on': 413, 'one': 414, 'opening': 415, 'opportunity': 416, 'or': 417, 'organic': 418, 'originality': 419, 'out': 420, 'outstanding': 421, 'over': 422, 'overacted': 423, 'overdone': 424, 'overdramatic': 425, 'overhyped': 426, 'overlong': 427, 'overly': 428, 'overproduced': 429, 'paced': 430, 'pacing': 431, 'painfully': 432, 'passion': 433, 'payoff': 434, 'perfect': 435, 'perfectly': 436, 'performance': 437, 'performances': 438, 'performed': 439, 'personality': 440, 'piece': 441, 'pitch': 442, 'plain': 443, 'plot': 444, 'point': 445, 'poor': 446, 'poorly': 447, 'portrayal': 448, 'possible': 449, 'powerful': 450, 'praise': 451, 'precise': 452, 'precision': 453, 'predictable': 454, 'pretentious': 455, 'produced': 456, 'production': 457, 'promising': 458, 'provoking': 459, 'pure': 460, 'purpose': 461, 'purposeful': 462, 'radiates': 463, 'random': 464, 'range': 465, 'rare': 466, 'real': 467, 'recommend': 468, 'refreshing': 469, 'refreshingly': 470, 'regret': 471, 'reignited': 472, 'relatable': 473, 'relate': 474, 'remarkable': 475, 'reminded': 476, 'remotely': 477, 'repetitive': 478, 'resonates': 479, 'restored': 480, 'rewatch': 481, 'rich': 482, 'ride': 483, 'ridiculous': 484, 'right': 485, 'rough': 486, 'ruined': 487, 'runtime': 488, 'rushed': 489, 'satisfied': 490, 'satisfying': 491, 'save': 492, 'say': 493, 'scene': 494, 'scenes': 495, 'score': 496, 'screen': 497, 'script': 498, 'second': 499, 'see': 500, 'seen': 501, 'sense': 502, 'sequel': 503, 'serious': 504, 'seriously': 505, 'shallow': 506, 'sharp': 507, 'shifted': 508, 'shines': 509, 'shot': 510, 'simplicity': 511, 'sincere': 512, 'sincerity': 513, 'single': 514, 'slightest': 515, 'sloppy': 516, 'slow': 517, 'small': 518, 'smiling': 519, 'so': 520, 'something': 521, 'soul': 522, 'soundtrack': 523, 'sparkled': 524, 'special': 525, 'spectacularly': 526, 'speechless': 527, 'spending': 528, 'stakes': 529, 'standout': 530, 'start': 531, 'stay': 532, 'stayed': 533, 'stiff': 534, 'still': 535, 'stop': 536, 'story': 537, 'storyline': 538, 'storytelling': 539, 'story’s': 540, 'stretched': 541, 'struggled': 542, 'stunning': 543, 'stunningly': 544, 'subplots': 545, 'substance': 546, 'subtle': 547, 'such': 548, 'superb': 549, 'supported': 550, 'supporting': 551, 'surprised': 552, 'surprises': 553, 'surprisingly': 554, 'symbolism': 555, 'take': 556, 'talented': 557, 'tears': 558, 'tension': 559, 'terrible': 560, 'than': 561, 'that': 562, 'the': 563, 'theater': 564, 'their': 565, 'themes': 566, 'there': 567, 'these': 568, 'think': 569, 'this': 570, 'those': 571, 'thought': 572, 'thoughtful': 573, 'thrilling': 574, 'through': 575, 'throughout': 576, 'tier': 577, 'tight': 578, 'time': 579, 'timed': 580, 'to': 581, 'told': 582, 'tone': 583, 'too': 584, 'top': 585, 'touched': 586, 'touching': 587, 'trailer': 588, 'tried': 589, 'triumph': 590, 'truly': 591, 'tv': 592, 'twists': 593, 'unbalanced': 594, 'unbearable': 595, 'unclear': 596, 'unconvincing': 597, 'undeniable': 598, 'underdeveloped': 599, 'underwhelming': 600, 'underwritten': 601, 'unearned': 602, 'uneven': 603, 'unfolded': 604, 'unforgettable': 605, 'uninspired': 606, 'uninteresting': 607, 'unmemorable': 608, 'unnatural': 609, 'unnecessary': 610, 'unoriginal': 611, 'unsatisfied': 612, 'unsatisfying': 613, 'up': 614, 'uplifting': 615, 'vision': 616, 'visual': 617, 'visually': 618, 'visuals': 619, 'wait': 620, 'want': 621, 'wants': 622, 'warm': 623, 'warmed': 624, 'warmth': 625, 'was': 626, 'waste': 627, 'watch': 628, 'watching': 629, 'way': 630, 'weak': 631, 'weight': 632, 'well': 633, 'went': 634, 'were': 635, 'what': 636, 'whatsoever': 637, 'why': 638, 'will': 639, 'with': 640, 'without': 641, 'witty': 642, 'wonder': 643, 'wonderful': 644, 'wonderfully': 645, 'work': 646, 'worked': 647, 'world': 648, 'worse': 649, 'would': 650, 'writing': 651, 'written': 652, 'year': 653, 'yet': 654, 'you': 655, 'you’ll': 656, 'zero': 657}\n"
          ]
        }
      ],
      "source": [
        "# 3. Build the Vocab\n",
        "# It will now automatically find and add the \"[CLS]\" token.\n",
        "all_words = set()\n",
        "for sentence, label in train_data: # <--- CHANGED FROM 'data'\n",
        "    # We must split based on spaces\n",
        "    words_in_sentence = sentence.lower().split(' ')\n",
        "    all_words.update(words_in_sentence)\n",
        "\n",
        "# Add <PAD> token\n",
        "vocab = {\"<PAD>\": 0}\n",
        "index = 1\n",
        "for word in sorted(list(all_words)):\n",
        "    vocab[word] = index\n",
        "    index += 1\n",
        "\n",
        "print(\"\\nYour new vocabulary (notice '[cls]' is in it):\")\n",
        "print(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0829-2fDRzxN",
        "outputId": "e7a32904-40ec-4cac-b552-88bca92bea28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test: '[CLS] I loved every second of it'\n",
            "Tensor: tensor([  2, 286, 355, 205, 499, 409, 312])\n"
          ]
        }
      ],
      "source": [
        "# Helper Function ---\n",
        "# make sure it splits by ' ' to handle the [CLS] token.\n",
        "def sentence_to_tensor(sentence, vocab_map):\n",
        "    \"\"\"Converts a string sentence to a tensor of integer IDs.\"\"\"\n",
        "    words = sentence.lower().split(' ') # Split by space\n",
        "    indices = [vocab_map.get(word, 0) for word in words] # 0 is <PAD>\n",
        "    return torch.tensor(indices, dtype=torch.long)\n",
        "\n",
        "\n",
        "test_sentence, _ = data[0]\n",
        "print(f\"\\nTest: '{test_sentence}'\")\n",
        "print(f\"Tensor: {sentence_to_tensor(test_sentence, vocab)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "SL7E5KjmSknh"
      },
      "outputs": [],
      "source": [
        "# We need this to create the positional encodings\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embed_dim, max_len=512):\n",
        "        super().__init__()\n",
        "        # Create a matrix for positional encodings\n",
        "        pe = torch.zeros(max_len, embed_dim)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(10000.0) / embed_dim))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        # 'register_buffer' makes it part of the model, but not a parameter to be trained\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is [batch, seq_len, embed_dim]\n",
        "        # We add our positional encodings (pe) to the word embeddings (x)\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return x\n",
        "\n",
        "class SentimentTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_heads, num_encoder_layers, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1. The Embedding Layer (SAME as before)\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # 2. The NEW Positional Encoding Layer\n",
        "        self.pos_encoder = PositionalEncoding(embedding_dim)\n",
        "\n",
        "        # 3. The NEW Transformer Encoder Layer\n",
        "        # This one object contains all the Q, K, V, Multi-Head Attention,\n",
        "        # and FeedForward logic inside it. It's a pre-built block.\n",
        "\n",
        "\n",
        "# [Image of the Transformer Encoder block architecture]\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embedding_dim,\n",
        "            nhead=n_heads,\n",
        "            batch_first=True # This is an important setting!\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=num_encoder_layers\n",
        "        )\n",
        "\n",
        "        # 4. The Final Output Layer (SAME as before)\n",
        "        # It takes the final vector (size embedding_dim)\n",
        "        # and squashes it to num_classes (2)\n",
        "        self.output_layer = nn.Linear(embedding_dim, num_classes)\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "    def forward(self, sentence_indices):\n",
        "        # 1. Get Embeddings (SAME as before)\n",
        "        # Input: [1, 7] (batch of 1 sentence, 7 words)\n",
        "        # Output: [1, 7, 32] (1 sentence, 7 words, 32-dim vectors)\n",
        "        X = self.embedding(sentence_indices.unsqueeze(0))\n",
        "\n",
        "        # 2. Add Positional Encodings\n",
        "        X = self.pos_encoder(X)\n",
        "\n",
        "        # 3. Run the Transformer \"reader\"\n",
        "        # X goes in [1, 7, 32]\n",
        "        # output comes out [1, 7, 32]\n",
        "        output = self.transformer_encoder(X)\n",
        "\n",
        "        # 4. Get the Final Prediction\n",
        "        # We only care about the *first* token's output\n",
        "        # (the [CLS] token)\n",
        "        cls_token_output = output[:, 0, :] # Select [batch, token_0, all_dims]\n",
        "\n",
        "        # 5. Pass it to the final layer\n",
        "        # [1, 32] -> [1, 2]\n",
        "        final_scores = self.output_layer(cls_token_output)\n",
        "\n",
        "        # Squeeze to remove the batch dim: [1, 2] -> [2]\n",
        "        return final_scores.squeeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model, Loss, and Optimizer are ready.\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "# These are the \"settings\" for our model\n",
        "VOCAB_SIZE = len(vocab)            # We get this from the vocab we just built\n",
        "EMBEDDING_DIM = 32                 # You can pick any size. 32 is small and fast\n",
        "N_HEADS = 4\n",
        "NUM_ENCODER_LAYERS = 2                 \n",
        "NUM_CLASSES = len(LABEL_MAP)       # This is 2 (Positive or Negative)\n",
        "LEARNING_RATE = 0.0001\n",
        "EPOCHS = 200                       # How many times to loop over the data\n",
        "\n",
        "# Initialization\n",
        "\n",
        "# 1. Create the model\n",
        "model = SentimentTransformer(VOCAB_SIZE, EMBEDDING_DIM, N_HEADS, NUM_ENCODER_LAYERS, NUM_CLASSES)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# 3. Create the \"mechanic\" (updates the model to make it better)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "print(\"Model, Loss, and Optimizer are ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Training ---\n",
            "Epoch   1/200 | Train Loss: 0.7285 | Test Loss: 0.6955 | Test Accuracy:   49.41%\n",
            "Epoch   2/200 | Train Loss: 0.7050 | Test Loss: 0.6913 | Test Accuracy:   49.41%\n",
            "Epoch   3/200 | Train Loss: 0.6973 | Test Loss: 0.6873 | Test Accuracy:   50.59%\n",
            "Epoch   4/200 | Train Loss: 0.6822 | Test Loss: 0.6876 | Test Accuracy:   49.41%\n",
            "Epoch   5/200 | Train Loss: 0.6421 | Test Loss: 0.6657 | Test Accuracy:   61.18%\n",
            "Epoch   6/200 | Train Loss: 0.5650 | Test Loss: 0.7079 | Test Accuracy:   61.18%\n",
            "Epoch   7/200 | Train Loss: 0.4608 | Test Loss: 0.7565 | Test Accuracy:   61.18%\n",
            "Epoch   8/200 | Train Loss: 0.4172 | Test Loss: 0.7010 | Test Accuracy:   67.06%\n",
            "Epoch   9/200 | Train Loss: 0.3385 | Test Loss: 0.8076 | Test Accuracy:   68.24%\n",
            "Epoch  10/200 | Train Loss: 0.2672 | Test Loss: 1.0863 | Test Accuracy:   62.35%\n",
            "Epoch  11/200 | Train Loss: 0.2803 | Test Loss: 1.1354 | Test Accuracy:   61.18%\n",
            "Epoch  12/200 | Train Loss: 0.2756 | Test Loss: 1.0076 | Test Accuracy:   64.71%\n",
            "Epoch  13/200 | Train Loss: 0.1984 | Test Loss: 1.2261 | Test Accuracy:   67.06%\n",
            "Epoch  14/200 | Train Loss: 0.1731 | Test Loss: 1.1999 | Test Accuracy:   65.88%\n",
            "Epoch  15/200 | Train Loss: 0.1323 | Test Loss: 1.0440 | Test Accuracy:   70.59%\n",
            "Epoch  16/200 | Train Loss: 0.1476 | Test Loss: 0.8622 | Test Accuracy:   72.94%\n",
            "Epoch  17/200 | Train Loss: 0.1015 | Test Loss: 1.0292 | Test Accuracy:   71.76%\n",
            "Epoch  18/200 | Train Loss: 0.1288 | Test Loss: 0.9241 | Test Accuracy:   72.94%\n",
            "Epoch  19/200 | Train Loss: 0.0898 | Test Loss: 0.6575 | Test Accuracy:   78.82%\n",
            "Epoch  20/200 | Train Loss: 0.0912 | Test Loss: 1.1041 | Test Accuracy:   69.41%\n",
            "Epoch  21/200 | Train Loss: 0.0864 | Test Loss: 0.9082 | Test Accuracy:   70.59%\n",
            "Epoch  22/200 | Train Loss: 0.0822 | Test Loss: 0.6156 | Test Accuracy:   80.00%\n",
            "Epoch  23/200 | Train Loss: 0.1006 | Test Loss: 0.8167 | Test Accuracy:   75.29%\n",
            "Epoch  24/200 | Train Loss: 0.0498 | Test Loss: 0.7901 | Test Accuracy:   78.82%\n",
            "Epoch  25/200 | Train Loss: 0.0528 | Test Loss: 1.0772 | Test Accuracy:   71.76%\n",
            "Epoch  26/200 | Train Loss: 0.0734 | Test Loss: 0.6577 | Test Accuracy:   76.47%\n",
            "Epoch  27/200 | Train Loss: 0.0528 | Test Loss: 0.9243 | Test Accuracy:   72.94%\n",
            "Epoch  28/200 | Train Loss: 0.0547 | Test Loss: 0.8973 | Test Accuracy:   77.65%\n",
            "Epoch  29/200 | Train Loss: 0.0312 | Test Loss: 1.1015 | Test Accuracy:   70.59%\n",
            "Epoch  30/200 | Train Loss: 0.0147 | Test Loss: 0.9415 | Test Accuracy:   78.82%\n",
            "Epoch  31/200 | Train Loss: 0.0156 | Test Loss: 0.8709 | Test Accuracy:   81.18%\n",
            "Epoch  32/200 | Train Loss: 0.0362 | Test Loss: 1.3365 | Test Accuracy:   71.76%\n",
            "Epoch  33/200 | Train Loss: 0.0752 | Test Loss: 0.8975 | Test Accuracy:   77.65%\n",
            "Epoch  34/200 | Train Loss: 0.0535 | Test Loss: 0.9835 | Test Accuracy:   72.94%\n",
            "Epoch  35/200 | Train Loss: 0.0335 | Test Loss: 1.4145 | Test Accuracy:   70.59%\n",
            "Epoch  36/200 | Train Loss: 0.0408 | Test Loss: 1.2562 | Test Accuracy:   71.76%\n",
            "Epoch  37/200 | Train Loss: 0.0178 | Test Loss: 0.8157 | Test Accuracy:   83.53%\n",
            "Epoch  38/200 | Train Loss: 0.0489 | Test Loss: 0.9350 | Test Accuracy:   75.29%\n",
            "Epoch  39/200 | Train Loss: 0.0076 | Test Loss: 1.3291 | Test Accuracy:   72.94%\n",
            "Epoch  40/200 | Train Loss: 0.0356 | Test Loss: 1.1862 | Test Accuracy:   72.94%\n",
            "Epoch  41/200 | Train Loss: 0.0215 | Test Loss: 0.9546 | Test Accuracy:   74.12%\n",
            "Epoch  42/200 | Train Loss: 0.0269 | Test Loss: 1.1427 | Test Accuracy:   74.12%\n",
            "Epoch  43/200 | Train Loss: 0.0354 | Test Loss: 0.9097 | Test Accuracy:   80.00%\n",
            "Epoch  44/200 | Train Loss: 0.0391 | Test Loss: 1.2363 | Test Accuracy:   70.59%\n",
            "Epoch  45/200 | Train Loss: 0.0408 | Test Loss: 0.7986 | Test Accuracy:   77.65%\n",
            "Epoch  46/200 | Train Loss: 0.0318 | Test Loss: 0.7330 | Test Accuracy:   80.00%\n",
            "Epoch  47/200 | Train Loss: 0.0102 | Test Loss: 0.7598 | Test Accuracy:   81.18%\n",
            "Epoch  48/200 | Train Loss: 0.0147 | Test Loss: 1.0554 | Test Accuracy:   76.47%\n",
            "Epoch  49/200 | Train Loss: 0.0333 | Test Loss: 1.0994 | Test Accuracy:   71.76%\n",
            "Epoch  50/200 | Train Loss: 0.0088 | Test Loss: 0.8615 | Test Accuracy:   78.82%\n",
            "Epoch  51/200 | Train Loss: 0.0400 | Test Loss: 0.8816 | Test Accuracy:   75.29%\n",
            "Epoch  52/200 | Train Loss: 0.0225 | Test Loss: 0.6964 | Test Accuracy:   84.71%\n",
            "Epoch  53/200 | Train Loss: 0.0293 | Test Loss: 0.6393 | Test Accuracy:   87.06%\n",
            "Epoch  54/200 | Train Loss: 0.0129 | Test Loss: 0.6144 | Test Accuracy:   88.24%\n",
            "Epoch  55/200 | Train Loss: 0.0042 | Test Loss: 0.7869 | Test Accuracy:   77.65%\n",
            "Epoch  56/200 | Train Loss: 0.0096 | Test Loss: 0.7691 | Test Accuracy:   83.53%\n",
            "Epoch  57/200 | Train Loss: 0.0434 | Test Loss: 0.8828 | Test Accuracy:   80.00%\n",
            "Epoch  58/200 | Train Loss: 0.0184 | Test Loss: 0.7473 | Test Accuracy:   82.35%\n",
            "Epoch  59/200 | Train Loss: 0.0264 | Test Loss: 0.8789 | Test Accuracy:   80.00%\n",
            "Epoch  60/200 | Train Loss: 0.0385 | Test Loss: 1.1698 | Test Accuracy:   74.12%\n",
            "Epoch  61/200 | Train Loss: 0.0239 | Test Loss: 0.6966 | Test Accuracy:   83.53%\n",
            "Epoch  62/200 | Train Loss: 0.0134 | Test Loss: 1.0140 | Test Accuracy:   76.47%\n",
            "Epoch  63/200 | Train Loss: 0.0025 | Test Loss: 1.1521 | Test Accuracy:   77.65%\n",
            "Epoch  64/200 | Train Loss: 0.0014 | Test Loss: 1.1741 | Test Accuracy:   75.29%\n",
            "Epoch  65/200 | Train Loss: 0.0123 | Test Loss: 0.8093 | Test Accuracy:   78.82%\n",
            "Epoch  66/200 | Train Loss: 0.0064 | Test Loss: 0.8427 | Test Accuracy:   78.82%\n",
            "Epoch  67/200 | Train Loss: 0.0261 | Test Loss: 1.0405 | Test Accuracy:   80.00%\n",
            "Epoch  68/200 | Train Loss: 0.0228 | Test Loss: 0.8722 | Test Accuracy:   78.82%\n",
            "Epoch  69/200 | Train Loss: 0.0081 | Test Loss: 1.3160 | Test Accuracy:   72.94%\n",
            "Epoch  70/200 | Train Loss: 0.0403 | Test Loss: 1.3451 | Test Accuracy:   71.76%\n",
            "Epoch  71/200 | Train Loss: 0.0261 | Test Loss: 0.8015 | Test Accuracy:   81.18%\n",
            "Epoch  72/200 | Train Loss: 0.0227 | Test Loss: 0.8265 | Test Accuracy:   81.18%\n",
            "Epoch  73/200 | Train Loss: 0.0274 | Test Loss: 0.6934 | Test Accuracy:   80.00%\n",
            "Epoch  74/200 | Train Loss: 0.0029 | Test Loss: 0.8231 | Test Accuracy:   80.00%\n",
            "Epoch  75/200 | Train Loss: 0.0018 | Test Loss: 0.7774 | Test Accuracy:   81.18%\n",
            "Epoch  76/200 | Train Loss: 0.0028 | Test Loss: 0.7236 | Test Accuracy:   82.35%\n",
            "Epoch  77/200 | Train Loss: 0.0037 | Test Loss: 0.7749 | Test Accuracy:   84.71%\n",
            "Epoch  78/200 | Train Loss: 0.0250 | Test Loss: 0.7516 | Test Accuracy:   82.35%\n",
            "Epoch  79/200 | Train Loss: 0.0057 | Test Loss: 1.0083 | Test Accuracy:   77.65%\n",
            "Epoch  80/200 | Train Loss: 0.0009 | Test Loss: 0.9744 | Test Accuracy:   78.82%\n",
            "Epoch  81/200 | Train Loss: 0.0508 | Test Loss: 0.6273 | Test Accuracy:   81.18%\n",
            "Epoch  82/200 | Train Loss: 0.0146 | Test Loss: 0.7809 | Test Accuracy:   82.35%\n",
            "Epoch  83/200 | Train Loss: 0.0142 | Test Loss: 0.6792 | Test Accuracy:   83.53%\n",
            "Epoch  84/200 | Train Loss: 0.0176 | Test Loss: 1.2726 | Test Accuracy:   72.94%\n",
            "Epoch  85/200 | Train Loss: 0.0056 | Test Loss: 0.7767 | Test Accuracy:   78.82%\n",
            "Epoch  86/200 | Train Loss: 0.0047 | Test Loss: 1.4393 | Test Accuracy:   72.94%\n",
            "Epoch  87/200 | Train Loss: 0.0133 | Test Loss: 1.0020 | Test Accuracy:   75.29%\n",
            "Epoch  88/200 | Train Loss: 0.0010 | Test Loss: 1.0278 | Test Accuracy:   76.47%\n",
            "Epoch  89/200 | Train Loss: 0.0009 | Test Loss: 1.0229 | Test Accuracy:   78.82%\n",
            "Epoch  90/200 | Train Loss: 0.0048 | Test Loss: 0.9615 | Test Accuracy:   80.00%\n",
            "Epoch  91/200 | Train Loss: 0.0298 | Test Loss: 0.9661 | Test Accuracy:   80.00%\n",
            "Epoch  92/200 | Train Loss: 0.0189 | Test Loss: 0.9212 | Test Accuracy:   82.35%\n",
            "Epoch  93/200 | Train Loss: 0.0019 | Test Loss: 0.9654 | Test Accuracy:   81.18%\n",
            "Epoch  94/200 | Train Loss: 0.0053 | Test Loss: 0.9599 | Test Accuracy:   76.47%\n",
            "Epoch  95/200 | Train Loss: 0.0268 | Test Loss: 0.8109 | Test Accuracy:   83.53%\n",
            "Epoch  96/200 | Train Loss: 0.0418 | Test Loss: 0.6749 | Test Accuracy:   82.35%\n",
            "Epoch  97/200 | Train Loss: 0.0028 | Test Loss: 0.7353 | Test Accuracy:   81.18%\n",
            "Epoch  98/200 | Train Loss: 0.0014 | Test Loss: 0.7414 | Test Accuracy:   81.18%\n",
            "Epoch  99/200 | Train Loss: 0.0011 | Test Loss: 0.7166 | Test Accuracy:   83.53%\n",
            "Epoch 100/200 | Train Loss: 0.0045 | Test Loss: 1.0381 | Test Accuracy:   78.82%\n",
            "Epoch 101/200 | Train Loss: 0.0042 | Test Loss: 1.0248 | Test Accuracy:   81.18%\n",
            "Epoch 102/200 | Train Loss: 0.0223 | Test Loss: 1.4095 | Test Accuracy:   75.29%\n",
            "Epoch 103/200 | Train Loss: 0.0112 | Test Loss: 0.9433 | Test Accuracy:   81.18%\n",
            "Epoch 104/200 | Train Loss: 0.0015 | Test Loss: 1.0080 | Test Accuracy:   75.29%\n",
            "Epoch 105/200 | Train Loss: 0.0007 | Test Loss: 1.1477 | Test Accuracy:   76.47%\n",
            "Epoch 106/200 | Train Loss: 0.0005 | Test Loss: 1.1837 | Test Accuracy:   77.65%\n",
            "Epoch 107/200 | Train Loss: 0.0005 | Test Loss: 1.2502 | Test Accuracy:   77.65%\n",
            "Epoch 108/200 | Train Loss: 0.0006 | Test Loss: 1.2232 | Test Accuracy:   76.47%\n",
            "Epoch 109/200 | Train Loss: 0.0245 | Test Loss: 1.1538 | Test Accuracy:   81.18%\n",
            "Epoch 110/200 | Train Loss: 0.0158 | Test Loss: 1.1472 | Test Accuracy:   77.65%\n",
            "Epoch 111/200 | Train Loss: 0.0049 | Test Loss: 1.1822 | Test Accuracy:   75.29%\n",
            "Epoch 112/200 | Train Loss: 0.0317 | Test Loss: 0.9814 | Test Accuracy:   78.82%\n",
            "Epoch 113/200 | Train Loss: 0.0059 | Test Loss: 1.2081 | Test Accuracy:   75.29%\n",
            "Epoch 114/200 | Train Loss: 0.0030 | Test Loss: 1.0533 | Test Accuracy:   76.47%\n",
            "Epoch 115/200 | Train Loss: 0.0014 | Test Loss: 1.0488 | Test Accuracy:   77.65%\n",
            "Epoch 116/200 | Train Loss: 0.0023 | Test Loss: 1.1166 | Test Accuracy:   82.35%\n",
            "Epoch 117/200 | Train Loss: 0.0036 | Test Loss: 1.2880 | Test Accuracy:   75.29%\n",
            "Epoch 118/200 | Train Loss: 0.0006 | Test Loss: 1.2775 | Test Accuracy:   76.47%\n",
            "Epoch 119/200 | Train Loss: 0.0003 | Test Loss: 1.2883 | Test Accuracy:   76.47%\n",
            "Epoch 120/200 | Train Loss: 0.0007 | Test Loss: 1.4096 | Test Accuracy:   75.29%\n",
            "Epoch 121/200 | Train Loss: 0.0016 | Test Loss: 1.3421 | Test Accuracy:   78.82%\n",
            "Epoch 122/200 | Train Loss: 0.0002 | Test Loss: 1.3444 | Test Accuracy:   78.82%\n",
            "Epoch 123/200 | Train Loss: 0.0002 | Test Loss: 1.3615 | Test Accuracy:   77.65%\n",
            "Epoch 124/200 | Train Loss: 0.0003 | Test Loss: 1.5074 | Test Accuracy:   76.47%\n",
            "Epoch 125/200 | Train Loss: 0.0284 | Test Loss: 1.4054 | Test Accuracy:   78.82%\n",
            "Epoch 126/200 | Train Loss: 0.0320 | Test Loss: 0.9666 | Test Accuracy:   77.65%\n",
            "Epoch 127/200 | Train Loss: 0.0009 | Test Loss: 1.0762 | Test Accuracy:   80.00%\n",
            "Epoch 128/200 | Train Loss: 0.0134 | Test Loss: 1.1623 | Test Accuracy:   78.82%\n",
            "Epoch 129/200 | Train Loss: 0.0200 | Test Loss: 0.9042 | Test Accuracy:   82.35%\n",
            "Epoch 130/200 | Train Loss: 0.0146 | Test Loss: 1.4433 | Test Accuracy:   75.29%\n",
            "Epoch 131/200 | Train Loss: 0.0018 | Test Loss: 1.0983 | Test Accuracy:   76.47%\n",
            "Epoch 132/200 | Train Loss: 0.0037 | Test Loss: 1.2359 | Test Accuracy:   78.82%\n",
            "Epoch 133/200 | Train Loss: 0.0004 | Test Loss: 1.2814 | Test Accuracy:   77.65%\n",
            "Epoch 134/200 | Train Loss: 0.0008 | Test Loss: 1.4155 | Test Accuracy:   78.82%\n",
            "Epoch 135/200 | Train Loss: 0.0024 | Test Loss: 1.5119 | Test Accuracy:   72.94%\n",
            "Epoch 136/200 | Train Loss: 0.0074 | Test Loss: 2.1997 | Test Accuracy:   68.24%\n",
            "Epoch 137/200 | Train Loss: 0.0036 | Test Loss: 1.0634 | Test Accuracy:   81.18%\n",
            "Epoch 138/200 | Train Loss: 0.0002 | Test Loss: 1.0785 | Test Accuracy:   78.82%\n",
            "Epoch 139/200 | Train Loss: 0.0004 | Test Loss: 1.1483 | Test Accuracy:   77.65%\n",
            "Epoch 140/200 | Train Loss: 0.0003 | Test Loss: 1.2313 | Test Accuracy:   77.65%\n",
            "Epoch 141/200 | Train Loss: 0.0002 | Test Loss: 1.2371 | Test Accuracy:   77.65%\n",
            "Epoch 142/200 | Train Loss: 0.0002 | Test Loss: 1.2368 | Test Accuracy:   76.47%\n",
            "Epoch 143/200 | Train Loss: 0.0321 | Test Loss: 1.5370 | Test Accuracy:   75.29%\n",
            "Epoch 144/200 | Train Loss: 0.0157 | Test Loss: 1.5374 | Test Accuracy:   75.29%\n",
            "Epoch 145/200 | Train Loss: 0.0009 | Test Loss: 1.6218 | Test Accuracy:   76.47%\n",
            "Epoch 146/200 | Train Loss: 0.0004 | Test Loss: 1.5602 | Test Accuracy:   75.29%\n",
            "Epoch 147/200 | Train Loss: 0.0006 | Test Loss: 1.4653 | Test Accuracy:   77.65%\n",
            "Epoch 148/200 | Train Loss: 0.0007 | Test Loss: 1.5338 | Test Accuracy:   77.65%\n",
            "Epoch 149/200 | Train Loss: 0.0269 | Test Loss: 1.3713 | Test Accuracy:   75.29%\n",
            "Epoch 150/200 | Train Loss: 0.0417 | Test Loss: 0.9550 | Test Accuracy:   78.82%\n",
            "Epoch 151/200 | Train Loss: 0.0120 | Test Loss: 1.0316 | Test Accuracy:   81.18%\n",
            "Epoch 152/200 | Train Loss: 0.0018 | Test Loss: 0.8987 | Test Accuracy:   78.82%\n",
            "Epoch 153/200 | Train Loss: 0.0009 | Test Loss: 0.9387 | Test Accuracy:   80.00%\n",
            "Epoch 154/200 | Train Loss: 0.0007 | Test Loss: 0.9998 | Test Accuracy:   81.18%\n",
            "Epoch 155/200 | Train Loss: 0.0012 | Test Loss: 1.1495 | Test Accuracy:   82.35%\n",
            "Epoch 156/200 | Train Loss: 0.0007 | Test Loss: 1.1680 | Test Accuracy:   75.29%\n",
            "Epoch 157/200 | Train Loss: 0.0002 | Test Loss: 1.1775 | Test Accuracy:   74.12%\n",
            "Epoch 158/200 | Train Loss: 0.0011 | Test Loss: 1.4933 | Test Accuracy:   77.65%\n",
            "Epoch 159/200 | Train Loss: 0.0019 | Test Loss: 1.2552 | Test Accuracy:   82.35%\n",
            "Epoch 160/200 | Train Loss: 0.0254 | Test Loss: 1.1314 | Test Accuracy:   80.00%\n",
            "Epoch 161/200 | Train Loss: 0.0412 | Test Loss: 0.9209 | Test Accuracy:   83.53%\n",
            "Epoch 162/200 | Train Loss: 0.0039 | Test Loss: 0.9061 | Test Accuracy:   80.00%\n",
            "Epoch 163/200 | Train Loss: 0.0179 | Test Loss: 0.9724 | Test Accuracy:   75.29%\n",
            "Epoch 164/200 | Train Loss: 0.0087 | Test Loss: 1.0681 | Test Accuracy:   76.47%\n",
            "Epoch 165/200 | Train Loss: 0.0009 | Test Loss: 1.0012 | Test Accuracy:   80.00%\n",
            "Epoch 166/200 | Train Loss: 0.0008 | Test Loss: 0.9331 | Test Accuracy:   77.65%\n",
            "Epoch 167/200 | Train Loss: 0.0007 | Test Loss: 0.9727 | Test Accuracy:   77.65%\n",
            "Epoch 168/200 | Train Loss: 0.0004 | Test Loss: 0.9279 | Test Accuracy:   77.65%\n",
            "Epoch 169/200 | Train Loss: 0.0224 | Test Loss: 0.8129 | Test Accuracy:   80.00%\n",
            "Epoch 170/200 | Train Loss: 0.0055 | Test Loss: 0.9359 | Test Accuracy:   83.53%\n",
            "Epoch 171/200 | Train Loss: 0.0051 | Test Loss: 0.8035 | Test Accuracy:   78.82%\n",
            "Epoch 172/200 | Train Loss: 0.0004 | Test Loss: 0.7996 | Test Accuracy:   78.82%\n",
            "Epoch 173/200 | Train Loss: 0.0025 | Test Loss: 0.9341 | Test Accuracy:   82.35%\n",
            "Epoch 174/200 | Train Loss: 0.0007 | Test Loss: 0.8656 | Test Accuracy:   78.82%\n",
            "Epoch 175/200 | Train Loss: 0.0002 | Test Loss: 0.8759 | Test Accuracy:   78.82%\n",
            "Epoch 176/200 | Train Loss: 0.0004 | Test Loss: 0.8783 | Test Accuracy:   78.82%\n",
            "Epoch 177/200 | Train Loss: 0.0002 | Test Loss: 0.8749 | Test Accuracy:   81.18%\n",
            "Epoch 178/200 | Train Loss: 0.0003 | Test Loss: 0.9252 | Test Accuracy:   85.88%\n",
            "Epoch 179/200 | Train Loss: 0.0002 | Test Loss: 0.9359 | Test Accuracy:   85.88%\n",
            "Epoch 180/200 | Train Loss: 0.0002 | Test Loss: 0.9351 | Test Accuracy:   82.35%\n",
            "Epoch 181/200 | Train Loss: 0.0002 | Test Loss: 1.0285 | Test Accuracy:   84.71%\n",
            "Epoch 182/200 | Train Loss: 0.0001 | Test Loss: 1.0223 | Test Accuracy:   85.88%\n",
            "Epoch 183/200 | Train Loss: 0.0002 | Test Loss: 1.0069 | Test Accuracy:   82.35%\n",
            "Epoch 184/200 | Train Loss: 0.0001 | Test Loss: 1.0141 | Test Accuracy:   82.35%\n",
            "Epoch 185/200 | Train Loss: 0.0001 | Test Loss: 1.0240 | Test Accuracy:   82.35%\n",
            "Epoch 186/200 | Train Loss: 0.0002 | Test Loss: 1.1264 | Test Accuracy:   81.18%\n",
            "Epoch 187/200 | Train Loss: 0.0001 | Test Loss: 1.1277 | Test Accuracy:   81.18%\n",
            "Epoch 188/200 | Train Loss: 0.0001 | Test Loss: 1.1331 | Test Accuracy:   81.18%\n",
            "Epoch 189/200 | Train Loss: 0.0001 | Test Loss: 1.1460 | Test Accuracy:   81.18%\n",
            "Epoch 190/200 | Train Loss: 0.0001 | Test Loss: 1.3109 | Test Accuracy:   81.18%\n",
            "Epoch 191/200 | Train Loss: 0.0316 | Test Loss: 1.3394 | Test Accuracy:   72.94%\n",
            "Epoch 192/200 | Train Loss: 0.0006 | Test Loss: 1.0922 | Test Accuracy:   78.82%\n",
            "Epoch 193/200 | Train Loss: 0.0001 | Test Loss: 1.0942 | Test Accuracy:   78.82%\n",
            "Epoch 194/200 | Train Loss: 0.0001 | Test Loss: 1.0998 | Test Accuracy:   78.82%\n",
            "Epoch 195/200 | Train Loss: 0.0001 | Test Loss: 1.1157 | Test Accuracy:   78.82%\n",
            "Epoch 196/200 | Train Loss: 0.0003 | Test Loss: 1.2221 | Test Accuracy:   78.82%\n",
            "Epoch 197/200 | Train Loss: 0.0006 | Test Loss: 1.0572 | Test Accuracy:   80.00%\n",
            "Epoch 198/200 | Train Loss: 0.0002 | Test Loss: 1.1440 | Test Accuracy:   80.00%\n",
            "Epoch 199/200 | Train Loss: 0.0004 | Test Loss: 1.5255 | Test Accuracy:   76.47%\n",
            "Epoch 200/200 | Train Loss: 0.0003 | Test Loss: 1.2511 | Test Accuracy:   77.65%\n",
            "--- Training Complete ---\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Starting Training ---\")\n",
        "\n",
        "# We loop for EPOCHS times\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    # --- 1. TRAINING PHASE ---\\\n",
        "    model.train()\n",
        "    \n",
        "    total_train_loss = 0\n",
        "    # Loop over every sentence for training\n",
        "    for sentence, label in train_data: # <--- CHANGED\n",
        "        \n",
        "        # 1. Clear old gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # 2. Prepare inputs\n",
        "        input_indices = sentence_to_tensor(sentence, vocab)\n",
        "        target_label = torch.tensor([label], dtype=torch.long)\n",
        "        \n",
        "        # 3. Forward pass (get the model's guess)\n",
        "        scores = model(input_indices) \n",
        "        \n",
        "        # 4. Calculate loss\n",
        "        loss = loss_function(scores.unsqueeze(0), target_label)\n",
        "        \n",
        "        # 5. Backward pass and optimize (The \"learning\" step)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "    # Calculate average training loss for this epoch\n",
        "    avg_train_loss = total_train_loss / len(train_data) # <--- CHANGED\n",
        "\n",
        "    # --- 2. EVALUATION PHASE ---\\\n",
        "    model.eval()\n",
        "    \n",
        "    total_eval_loss = 0\n",
        "    correct_count = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for sentence, label in test_data: # <--- CHANGED\n",
        "            \n",
        "            # 1. Prepare inputs (same as before)\n",
        "            input_indices = sentence_to_tensor(sentence, vocab)\n",
        "            target_label = torch.tensor([label], dtype=torch.long)\n",
        "            \n",
        "            # 2. Forward pass (get the model's guess)\n",
        "            scores = model(input_indices)\n",
        "            \n",
        "            # 3. Calculate loss (for this test data)\n",
        "            loss = loss_function(scores.unsqueeze(0), target_label)\n",
        "            total_eval_loss += loss.item()\n",
        "            \n",
        "            # 4. Calculate accuracy\n",
        "            predicted_class = torch.argmax(scores).item()\n",
        "            if predicted_class == label:\n",
        "                correct_count += 1\n",
        "    \n",
        "    # Calculate average loss and accuracy for this epoch\n",
        "    avg_eval_loss = total_eval_loss / len(test_data) # <--- CHANGED\n",
        "    epoch_accuracy = (correct_count / len(test_data)) * 100 # <--- CHANGED\n",
        "\n",
        "    # --- 3. PRINT RESULTS FOR THE EPOCH ---\\\n",
        "    # Renamed \"Eval Loss\" to \"Test Loss\" and \"Accuracy\" to \"Test Accuracy\" for clarity\n",
        "    print(f\"Epoch {epoch+1:3}/{EPOCHS} | Train Loss: {avg_train_loss:.4f} | Test Loss: {avg_eval_loss:.4f} | Test Accuracy: {epoch_accuracy:7.2f}%\") # <--- CHANGED\n",
        "\n",
        "print(\"--- Training Complete ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Confusion Matrix ---\n",
            "[[32 11]\n",
            " [ 8 34]]\n",
            "\n",
            "(Rows are 'Actual', Columns are 'Predicted')\n",
            "       Negative  Positive\n",
            "Actual Negative: [32 11]\n",
            "Actual Positive: [ 8 34]\n",
            "\n",
            "\n",
            "--- Classification Report ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.80      0.74      0.77        43\n",
            "    Positive       0.76      0.81      0.78        42\n",
            "\n",
            "    accuracy                           0.78        85\n",
            "   macro avg       0.78      0.78      0.78        85\n",
            "weighted avg       0.78      0.78      0.78        85\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# 1. We need to collect all the \"true\" labels and all the \"predicted\" labels\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# --- ADD THIS LINE TO FIX THE ERROR ---\n",
        "# This creates the {0: \"Negative\", 1: \"Positive\"} map\n",
        "LABEL_REVERSE_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
        "# -------------------------------------\n",
        "\n",
        "# Put the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# We don't need to calculate gradients here, so we use torch.no_grad()\n",
        "with torch.no_grad():\n",
        "    # Loop over our TEST data\n",
        "    for sentence, label in test_data:\n",
        "        \n",
        "        # Get the model's prediction\n",
        "        input_indices = sentence_to_tensor(sentence, vocab)\n",
        "        scores = model(input_indices)\n",
        "        predicted_class = torch.argmax(scores).item()\n",
        "        \n",
        "        # Add the true label and the predicted label to our lists\n",
        "        y_true.append(label)\n",
        "        y_pred.append(predicted_class)\n",
        "\n",
        "# 2. Now, just print the reports!\n",
        "\n",
        "print(\"--- Confusion Matrix ---\")\n",
        "# This line will now work correctly\n",
        "label_names = [LABEL_REVERSE_MAP[i] for i in range(len(LABEL_REVERSE_MAP))]\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(cm)\n",
        "print(\"\\n(Rows are 'Actual', Columns are 'Predicted')\")\n",
        "print(f\"       {label_names[0]}  {label_names[1]}\")\n",
        "print(f\"Actual {label_names[0]}: {cm[0]}\")\n",
        "print(f\"Actual {label_names[1]}: {cm[1]}\")\n",
        "\n",
        "\n",
        "print(\"\\n\\n--- Classification Report ---\")\n",
        "# This report gives you Precision, Recall, and F1-Score all at once\n",
        "report = classification_report(y_true, y_pred, target_names=label_names)\n",
        "print(report)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "carepd310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
